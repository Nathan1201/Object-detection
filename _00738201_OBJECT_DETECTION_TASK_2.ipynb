{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Before we start, remember we do not need to run on GPU because we are not training any model.**"
      ],
      "metadata": {
        "id": "sF6hNU2r1Zzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU check (optional)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MISACibt1p9g",
        "outputId": "3f6c28b1-f36a-4b01-b626-7295b7d9099c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install YOLOv11**\n",
        "Install the Ultralytics package, along with all required dependencies, in a Python environment (version 3.8 or higher) with PyTorch (version 1.8 or higher) using the following command: pip install ultralytics."
      ],
      "metadata": {
        "id": "kCF9IAHn2RHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Ultralytics YOLO package\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aph5Da-93i2w",
        "outputId": "cf2fe007-3fa7-4168-e417-f5a3e6e2599e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.48 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 32.7/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the current working directory and create a data folder\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "!mkdir -p {HOME}/data\n"
      ],
      "metadata": {
        "id": "py9cNBN23z4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "5ylyW00p4glD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the video to the Environment\n",
        "%cd {HOME}\n",
        "source_video = f\"{HOME}/vehicle-counting.mp4\"\n",
        "display.clear_output()\n"
      ],
      "metadata": {
        "id": "gC8Z-M3v4nil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a model\n",
        "You can now choose the core model for your object tracking tasks; object detection, the corresponding checkpoints will be automatically downloaded."
      ],
      "metadata": {
        "id": "kyO2xl0ZB1j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLO model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolo11n-seg.pt\")\n"
      ],
      "metadata": {
        "id": "G-ujx-ts5sXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03e98b3-73b8-4997-aa03-5fab564bdb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.90M/5.90M [00:00<00:00, 54.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ByteTrack Installation through Roboflow Supervision**"
      ],
      "metadata": {
        "id": "igAMZwk8Cj_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roboflow Supervision Installation**"
      ],
      "metadata": {
        "id": "Hi_WMqiJPvCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install supervision (used for visualization and tracking)\n",
        "!pip install supervision\n",
        "\n",
        "display.clear_output()\n"
      ],
      "metadata": {
        "id": "fVI0Vdr_5y5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0QWmr3uuV20Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Required Library**"
      ],
      "metadata": {
        "id": "urKGI14WHTpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "import supervision as sv\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "xPXU4yVNHaTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialization**\n",
        "\n",
        "Limit the model to focus exclusively on the objects of interest. Additionally, since the goal is to count moving objects, you can define a specific region in the videoâ€”preferably closer to the cameraâ€”to track and count these objects. To achieve this, the region's coordinates should be specified."
      ],
      "metadata": {
        "id": "cNAo2BBrf23k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class names and IDs of interest (e.g., cars and trucks)\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "class_ids = [2, 7]\n",
        "\n",
        "# Define counting line coordinates (adjusted based on video dimensions)\n",
        "start = sv.Point(0, 1350)  # Starting point of the line\n",
        "end = sv.Point(3840, 1350)  # Ending point of the line\n",
        "\n",
        "# Target video path\n",
        "target_video = f\"{HOME}/result.mp4\"\n"
      ],
      "metadata": {
        "id": "zp9lebKWJB1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse the input video.\n",
        "And create a VideoInfo instance"
      ],
      "metadata": {
        "id": "w9RDVNkby7oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the input video and create a VideoInfo instance\n",
        "video_info = sv.VideoInfo.from_video_path(source_video)\n"
      ],
      "metadata": {
        "id": "pMq66APzzyQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ByteTrack instance."
      ],
      "metadata": {
        "id": "fevqbDtr0DI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ByteTrack instance for object tracking\n",
        "byte_tracker = sv.ByteTrack(\n",
        "    track_activation_threshold=0.25,\n",
        "    lost_track_buffer=30,\n",
        "    minimum_matching_threshold=0.8,\n",
        "    frame_rate=30,\n",
        "    minimum_consecutive_frames=3\n",
        ")\n",
        "\n",
        "byte_tracker.reset()"
      ],
      "metadata": {
        "id": "fYO2MuQM0E-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect YOLO to ByteTrack"
      ],
      "metadata": {
        "id": "4b8B6ctJ0X4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect YOLO to ByteTrack\n",
        "\n",
        "# Create a generator for video frames\n",
        "generator = sv.get_video_frames_generator(source_video)\n",
        "\n",
        "# Create LineZone instance for vehicle counting\n",
        "line_zone = sv.LineZone(start=start, end=end)\n",
        "\n",
        "# Create annotators for visualization\n",
        "box_annotator = sv.BoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)\n",
        "trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
        "line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# Define the callback function for processing each frame\n",
        "def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
        "    # YOLO model prediction and convert results to Supervision detections\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    # Filter detections to include only specified class IDs\n",
        "    detections = detections[np.isin(detections.class_id, class_ids)]\n",
        "\n",
        "    # Track the detections\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "    # Generate labels for visualization\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "        for confidence, class_id, tracker_id\n",
        "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "\n",
        "    # Annotate the frame\n",
        "    annotated_frame = frame.copy()\n",
        "    annotated_frame = trace_annotator.annotate(\n",
        "        scene=annotated_frame, detections=detections\n",
        "    )\n",
        "    annotated_frame = box_annotator.annotate(\n",
        "        scene=annotated_frame, detections=detections\n",
        "    )\n",
        "    annotated_frame = label_annotator.annotate(\n",
        "        scene=annotated_frame, detections=detections, labels=labels\n",
        "    )\n",
        "\n",
        "    # Update the LineZone for counting\n",
        "    line_zone.trigger(detections)\n",
        "\n",
        "    # Annotate the LineZone on the frame\n",
        "    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
        "\n",
        "    %matplotlib inline\n",
        "    show_frame_in_notebook(frame, (16, 16))\n"
      ],
      "metadata": {
        "id": "E3ZdezKa0ZeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the video and save the final output"
      ],
      "metadata": {
        "id": "oLsKqHtw1As9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Process the video and save the output\n",
        "sv.process_video(\n",
        "    source_path = source_video,\n",
        "    target_path = target_video,\n",
        "    callback=callback\n",
        ")"
      ],
      "metadata": {
        "id": "EgQF3s5J4MbR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}